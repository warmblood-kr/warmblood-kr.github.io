---
layout: post
title: "코칭 관점에서 본 AI 대화의 기술"
date: 2025-11-25 13:30:00 +0900
categories: techstack
author: jeongsoo.park
description: LLM에게 컨텍스트 엔지니어링을 한다는 건 단순한 프롬프트 설계가 아니라, '대화의 깊이'를 만들어 가는 과정입니다. 그리고 이 과정은 코칭의 원리와 생각보다 닮아 있습니다.
image: "/images/2025-11-25-coaching-skill-to-llm.jpg"
---

저는 "성찰적인 업무 방식"을 중시합니다. 매일 반복되는 프로젝트 속에서도 작게 돌아보며, 일의 방식이나 사고의 구조를 개선하려는 작은 실험들을 꾸준히 해왔습니다. 이것은 LLM을 이용한 작업에서도 마찬가지입니다.

몆달 전 동료분과 함께 '페어 AI 증강 코딩'을 하고 난 후 문득 이런 생각이 들었습니다. 라이프 코치의 시선으로 본 LLM 컨텍스트 엔지니어링 팁을 써볼 수 있겠다는 것이었습니다.

저는 지난 10여 년간 100명 넘는 사람들을 코칭하고 멘토링해왔고, 그 경험을 통해 배워온 '대화의 기술'이 AI와 협업할 때도 쓰일 수 있지 않을까 싶었습니다.

그리고, 지금 그 생각을 다시 꺼내봅니다 — LLM에게 컨텍스트 엔지니어링을 한다는 건 단순한 프롬프트 설계가 아니라, '대화의 깊이'를 만들어 가는 과정입니다. 그리고 이 과정은 코칭의 원리와 생각보다 닮아 있습니다.


![Apply coaching skill to LLM](/images/2025-11-25-coaching-skill-to-llm.jpg)


## GROW 모델: 목표와 탐색의 구조를 가져오기

코칭의 대표적인 프레임워크인 **GROW 모델(Goal–Reality–Options–Will)**은 컨텍스트 엔지니어링에도 유용합니다.

GROW 모델 먼저 **목표(Goal)**를 명확히 정의하고, 현재의 **현실(Reality)**을 점검하며, 가능한 **옵션(Options)**을 여럿 펼쳐보고, 실제로 어떤 방향으로 **실행(Will)**할지 결정하는 흐름을 만들어냅니다.

프롬프트를 설계할 때도 이 구조를 그대로 적용할 수 있습니다. 단순히 "코드를 써줘"가 아니라, "이 기능의 목표는 사용자가 5초 안에 결과를 확인하는 것이고, 현재는 15초가 걸리며, 병목은 데이터베이스 쿼리에 있습니다. 캐싱, 인덱스 최적화, 쿼리 재작성 등의 옵션을 비교해서 가장 현실적인 방안을 제시해주세요."라는 식으로 접근할 수 있습니다.

특히 중요한 것은 '전형적인 대안'에서 벗어나기입니다. 코칭에서도 피코치가 습관적으로 떠올리는 해결책만 붙들고 있을 때, 코치는 "완전히 다른 방향으로 생각해본다면?" 같은 질문을 던집니다. LLM과의 대화에서도 마찬가지입니다. "일반적인 방법 말고, 완전히 다른 접근 3가지를 제시해주세요."라고 요청하면, LLM은 사고 공간을 확장하며 우리가 미처 생각하지 못한 옵션을 보여주곤 합니다.

또한 각 옵션에 대해 현실 가능성과 장애물을 탐색하는 것도 중요합니다. "이 방법을 실제로 구현할 때 예상되는 문제점은?", "기존 시스템과의 호환성은?", "팀의 기술 스택에서 실현 가능한가?" 같은 질문을 덧붙이면, LLM은 단순 제안을 넘어 구체적인 실행 계획까지 함께 그려냅니다.

결국 GROW 모델을 프롬프트에 녹여내는 것은, LLM과의 대화를 구조화된 문제해결 프로세스로 만드는 일입니다. 그리고 그 구조 안에서 우리의 사고도 함께 정리됩니다.


## 단순 지시보다 '의도와 이유'를 공유하기

"이거 해줘", "저거 만들어봐"로는 충분치 않습니다.

코칭에서 코치는 지시하지 않습니다. 대신 피코치가 스스로 생각하도록 '맥락의 이유'를 탐색해줍니다. "그걸 왜 하고 싶으세요?", "그게 당신에게 어떤 의미가 있나요?", "그 선택의 배경은 무엇인가요?" 같은 질문을 통해 피코치 스스로 자신의 의도를 명확히 하게 만듭니다.

흥미롭게도, 코치는 자신의 행동의 이유나 배경을 피코치에게 설명하지는 않지만, 피코치의 것을 듣는 훈련을 끊임없이 합니다. 그래서 상대의 의도를 잘 캐내고 파악합니다. 그리고 이런 훈련을 하다 보면, 역설적으로 자신의 내면을 읽는 훈련도 되기 때문에 자신의 의도와 배경도 더 명료하게 설명할 수 있게 됩니다.

LLM과 대화할 때도 그렇습니다. 요청을 할 때 '왜 이런 방향으로 생각하는지', '배경이 무엇인지', '목표가 무엇인지'를 함께 설명하는 프롬프트가 컨텍스트를 훨씬 풍부하게 만듭니다.

예를 들어, "사용자 인증 로직을 JWT로 바꿔줘" 대신 "현재 세션 기반 인증은 서버 메모리 부담이 크고, 마이크로서비스 아키텍처로 전환하면서 상태 공유가 어려워졌다. JWT 방식으로 전환하되, 보안상 refresh token 로테이션도 함께 구현해야 한다. 이 배경을 고려해서 설계해줘"라고 요청하면, LLM의 응답 품질이 확연히 달라집니다.

더 나아가, LLM이 제안한 내용에 대해서도 같은 방식으로 물어볼 수 있습니다. "이 접근법을 선택한 이유는?", "다른 옵션 대비 장점은?", "이 구현이 가정하는 전제조건은?" 같은 질문을 통해, LLM이 단순히 정답을 내놓는 봇이 아니라 문제공간을 함께 탐색하는 파트너로 작동하게 됩니다.

의도와 이유를 공유한다는 것은 결국, 대화의 맥락을 입체적으로 만드는 일입니다. 그리고 그 맥락 안에서 LLM은 훨씬 더 정교하고 상황에 맞는 답변을 생성해냅니다.


## 언어와 심상의 일치: 개념어의 힘

코칭에서는 'parrot phrase', 즉 상대의 말을 되짚어 주는 방식으로 심상을 맞춰갑니다.

피코치가 "뭔가 답답해요"라고 말하면, 코치는 "답답하시군요"라고 되받아주며 그 감정의 결을 함께 느낍니다. 그리고 조금씩 더 구체적인 언어로 좁혀갑니다. "어떤 종류의 답답함인가요?", "가슴이 막히는 느낌인가요, 아니면 출구가 안 보이는 느낌인가요?" 이런 식으로 개념어를 섬세하게 사용하면서, 내담자가 머릿속에서 떠올리는 것을 코치의 머릿속에도 같은 그림으로 떠오르게 만듭니다.

반대로, 코치가 머릿속에 떠오른 것도 내담자의 머릿속에 그림처럼 연상될 수 있게 전달합니다. "마치 안개 속을 걷는 것 같은 느낌이시군요"라고 말하면, 내담자는 "맞아요, 정확히 그 느낌이에요!"라고 반응합니다. 이것이 바로 언어를 통한 심상의 일치입니다.

LLM과의 대화에서도 개념어를 정교하게 쓰는 것이 중요합니다.

"성능을 개선해줘" 대신 "응답 시간(latency)을 줄여줘", "처리량(throughput)을 높여줘", "메모리 사용량(memory footprint)을 최적화해줘"처럼 구체적인 기술 개념어를 사용하면, LLM은 훨씬 더 정확한 방향으로 사고합니다.

또한 도메인 특화 용어를 명확히 정의하고 사용하는 것도 중요합니다. "유저"라는 말 대신 "임차인(tenant)", "임대인(landlord)", "중개인(agent)" 같은 도메인의 정확한 개념어를 사용하면, LLM이 생성하는 코드나 로직이 비즈니스 맥락과 훨씬 더 잘 맞아떨어집니다.

이것은 단순한 기술적 정교함이 아니라, 인지적 정렬(cognitive alignment)을 만들어내는 일입니다. 우리가 사용하는 언어가 곧 우리가 생각하는 구조를 형성하고, LLM은 그 언어 구조 안에서 추론합니다. 언어를 통해 서로의 심상이 일치할 때, LLM이 생성하는 콘텐츠는 사용자의 사고 흐름과 자연스럽게 맞닿게 됩니다.

개념어를 섬세하게 다룬다는 것은, 결국 사고의 해상도를 높이는 일입니다. 그리고 그 해상도가 바로 컨텍스트의 품질을 결정짓는 핵심입니다.

![concept alignment between human and LLM](/images/2025-11-25-concept-alignment.jpg)

## 라이프 코칭 vs LLM 코칭: 의지의 부재와 질문의 전환

코칭에서는 종종 "이것이 당신에게 어떤 의미인가요?"와 같은 존재적 질문을 던집니다.

이런 질문은 피코치가 자신의 내면을 들여다보고, 진짜 원하는 것이 무엇인지, 왜 그것을 원하는지 탐색하게 만듭니다. "이 목표를 이루면 당신의 삶은 어떻게 달라지나요?", "이것이 당신의 정체성에 어떤 의미를 갖나요?" 같은 질문은 단순한 문제해결을 넘어, 피코치의 존재와 가치관을 건드립니다.

그러나 LLM은 '의지'를 가진 존재가 아닙니다. LLM에게 "이 코드가 너에게 어떤 의미야?"라고 물어봐야 아무 소용이 없습니다. LLM은 의미를 느끼지 못하고, 동기도 없으며, 존재적 고민도 하지 않습니다.

따라서 LLM과의 대화에서는 의미 탐색보다 문제구조적 질문, 해결적 질문이 훨씬 효과적입니다.

"이 문제를 다른 관점에서 보면 어떻게 정의할 수 있을까?", "이 접근의 전제조건은 무엇이고, 그 전제가 깨지면 어떤 일이 벌어질까?", "이 솔루션의 장애물은 무엇이고, 그걸 우회하는 다른 경로는?", "이 구조의 trade-off는 무엇일까?" 같은 질문들입니다.

이런 질문은 LLM의 추론 공간을 구조화하고, 문제를 여러 각도에서 분해하고 재구성하게 만듭니다. 마치 코칭에서 "이 문제를 다르게 표현하면 어떻게 될까요?"라고 묻는 것처럼, LLM에게도 "이 요구사항을 기술적 제약조건으로 풀어서 다시 정의해줘"라고 요청할 수 있습니다.

LLM에게 묻는 질문은 곧 사고의 구조를 설계하는 작업입니다. 질문의 방향이 명확할수록, LLM의 추론 폭은 넓어지고, 맥락적으로 더 깊은 대화를 가능하게 만듭니다.

존재적 질문은 사람에게, 구조적 질문은 LLM에게 — 이 차이를 이해하는 것이 효과적인 컨텍스트 엔지니어링의 출발점입니다.


## 관계의 힘: 나와 LLM 사이의 연결통로

코칭에서는 코칭이 코치의 능력이나 클라이언트의 능력만이 아니라 그 사이의 관계, 연결통로의 힘에서 일어난다고 말합니다.

아무리 뛰어난 코치라도, 피코치와의 신뢰가 없으면 아무 일도 일어나지 않습니다. 반대로 평범한 코치라도, 피코치와의 대화가 안전하고 진솔하게 흐르면, 놀라운 변화가 일어나곤 합니다. 코칭의 마법은 코치 개인의 지식이 아니라, 대화라는 공간 안에서 만들어지는 연결에 있습니다.

LLM과의 대화도 비슷합니다.

LLM이 '문제해결 능력'을 단독으로 갖는 것이 아닙니다. 실제로는, 대화를 통해 문제와 해결책이 언어로 해석되고 명료해지는 과정이 핵심입니다.

우리가 문제를 막연하게 느낄 때, 그것을 언어로 풀어서 설명하는 순간, 문제의 윤곽이 드러나기 시작합니다. "왜 느린가?" → "어느 구간에서 느린가?" → "데이터베이스 쿼리인가, 네트워크 지연인가?" → "쿼리라면 어떤 테이블의 어떤 조인에서 병목이 생기는가?" 이렇게 언어로 풀어가는 과정에서, 문제는 점점 선명해집니다.

LLM은 이 과정에서 사고의 파트너로 작동합니다. 우리가 던진 질문에 응답하면서, 우리의 사고를 확장하고, 놓친 부분을 짚어주고, 다른 가능성을 제시합니다. 그리고 우리는 그 응답을 보면서 다시 생각을 정리하고, 더 정교한 질문을 던집니다.

이것은 마치 코칭 대화에서 코치와 피코치가 주고받는 언어의 춤과 같습니다. 코치가 질문하면 피코치가 답하고, 그 답을 듣고 코치가 다시 질문하고, 그 과정에서 피코치의 생각이 점점 명료해지는 것처럼, LLM과의 대화도 반복적으로 명료화되는 과정입니다.

결국 핵심은, 나와 LLM의 대화가 빙빙 돌고 있는가, 혹은 문제와 해결책을 점점 선명하게 드러내는 방향으로 진전하고 있는가입니다.

대화가 진전한다는 것은, 애매했던 것이 구체화되고, 모호했던 것이 명확해지고, 가능성들이 좁혀지면서 실행 가능한 옵션이 드러나는 것을 의미합니다.

컨텍스트 엔지니어링이란 바로 이 '진전하는 대화의 힘'을 설계하는 일입니다. 단순히 좋은 프롬프트 하나를 던지는 게 아니라, 여러 차례의 대화를 통해 사고가 깊어지고 문제가 풀리는 흐름을 만드는 것입니다.


## 나가는 말

LLM과 협업한다는 건, 단순히 모델을 다루는 기술이 아니라 대화의 품질을 설계하는 일입니다.

코칭처럼, 우리가 던지는 언어와 맥락이 AI의 사고공간을 형성합니다. 좋은 질문이 좋은 답을 만들어내고, 명확한 개념어가 정확한 추론을 이끌어냅니다.

결국 좋은 프롬프트란 명령이 아니라 대화의 구조이며, AI와 함께 사고를 확장하는 실험입니다.

10년간 100여 명을 코칭해온 경험이 LLM과의 대화에 자연스럽게 녹아든다는 것은, 결국 대화의 본질은 같다는 뜻일지도 모릅니다. 상대가 사람이든 AI이든, 언어를 통해 사고를 펼치고 문제를 명료하게 만드는 과정은 닮아 있습니다.

앞으로도 우리는 LLM과 더 많이 대화하게 될 것입니다. 그 대화를 단순한 명령의 나열이 아니라, 함께 사고하는 여정으로 만들 수 있다면, AI는 단순한 도구를 넘어 진짜 협업 파트너가 될 것입니다.
